{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is about training a unet on the difference between consecutive frames and difference of corresponding needle pixel masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 110*20 = 2200 amount of total frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_DIFF = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all files from necessary directory\n",
    "from utils.labels_utils import get_all_files_mhd\n",
    "all_files_mhd = get_all_files_mhd(\"/data/Riabova/train/train_depth_0_70/\")\n",
    "len(all_files_mhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 0...\n",
      "File 20...\n",
      "File 40...\n",
      "File 60...\n",
      "File 80...\n",
      "File 100...\n"
     ]
    }
   ],
   "source": [
    "from utils.type_reader import mha_read_header\n",
    "import numpy as np\n",
    "from utils.labels_utils import get_labels\n",
    "from tqdm import tqdm\n",
    "\n",
    "# merge all images in one huge array\n",
    "\n",
    "all_frames_filenames_array = np.empty((1))\n",
    "frame_nums = np.empty((1))\n",
    "labels = np.empty((1, 3))\n",
    "i = 0\n",
    "for f in all_files_mhd:\n",
    "    if (i%20 == 0):\n",
    "        print(\"File \"+str(i)+\"...\")\n",
    "    info = mha_read_header(f)\n",
    "    labels = np.concatenate((labels, get_labels(f, info)[FRAME_DIFF:]), axis = 0)\n",
    "    all_frames_filenames_array = np.concatenate((all_frames_filenames_array, [f]*(info['Dimensions'][3]-FRAME_DIFF)), axis=0)\n",
    "    frame_nums = np.concatenate((frame_nums, np.arange(0, info['Dimensions'][3]-FRAME_DIFF, dtype=int)), axis=0)\n",
    "    i+=1\n",
    "    \n",
    "all_frames_filenames_array = all_frames_filenames_array[ 1:]\n",
    "labels = labels[1:, :]\n",
    "frame_nums = frame_nums[1:]\n",
    "second_frame_nums = frame_nums+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2026, 3)\n",
      "['/data/Riabova/train/train_depth_0_70/10_0_-3_0_0_0_4_2_1689851213927661.mhd'\n",
      " '0.0' '2.0']\n",
      "[109.4285235 109.4948    125.6625   ]\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((all_frames_filenames_array, frame_nums, second_frame_nums)).transpose()\n",
    "y = labels\n",
    "print(X.shape)\n",
    "print(X[0, :])\n",
    "print(y[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_PERCENT = 0.2\n",
    "TEST_PERCENT = 0.2\n",
    "BATCH_TRAIN = 10\n",
    "BATCH_VALID = 10\n",
    "BATCH_TEST = 10\n",
    "RESIZE_TO = 128 # original size - 235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 1215\n",
      "Total validation images: 405\n",
      "Total test images: 406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_vt, y_train, y_vt = train_test_split(X[:, :], y[:, :], test_size=VALID_PERCENT+TEST_PERCENT, random_state=42, shuffle = True)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_vt[:, :], y_vt[:, :], test_size=TEST_PERCENT/(VALID_PERCENT+TEST_PERCENT), random_state=42,shuffle=True)\n",
    "print(f\"Total training images: {X_train.shape[0]}\")\n",
    "print(f\"Total validation images: {X_valid.shape[0]}\")\n",
    "print(f\"Total test images: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import FrameDiffDataset, my_collate\n",
    "import torch\n",
    "\n",
    "train_dataset = FrameDiffDataset(X_train, y_train, resizeTo=RESIZE_TO)\n",
    "valid_dataset = FrameDiffDataset(X_valid, y_valid, resizeTo=RESIZE_TO)\n",
    "test_dataset = FrameDiffDataset(X_test, y_test, resizeTo=RESIZE_TO)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_TRAIN,shuffle=True, collate_fn=my_collate)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset,batch_size=BATCH_VALID,shuffle=True, collate_fn=my_collate)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_TEST,shuffle=True, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init number of epochs to train for, and the\n",
    "# batch size of train and validation sets\n",
    "EPOCHS = 50\n",
    "UNET_DEPTH = 4 # size of the image should divide by this number\n",
    "UNET_START_FILTERS = 3\n",
    "\n",
    "#For LR scheduler\n",
    "INIT_LR = 0.001\n",
    "WEIGHT_DECAY = 1e-8\n",
    "MOMENTUM = 0.999\n",
    "\n",
    "# define threshold to filter weak predictions\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device will be 'cuda' if a GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from models.unet import UNet\n",
    "from utils.losses import IoULossModified\n",
    "from utils.save_model_utils import SaveBestModel\n",
    "\n",
    "model = UNet(out_channels = 1, n_blocks=UNET_DEPTH, start_filts = UNET_START_FILTERS)\n",
    "optimizer = optim.Adam(model.parameters()) #optim.RMSprop(model.parameters(),lr=INIT_LR, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM, foreach=True)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "criterion = IoULossModified()\n",
    "save_best_model = SaveBestModel('outputs_frames_diff/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from utils.save_model_utils import save_model, save_plots, save_sample_mask\n",
    "from utils.accuracies import get_central_pixel_distance, get_pixel_accuracy_percent\n",
    "\n",
    "class TrainerUNET:\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset = None,\n",
    "                 lr_scheduler: torch.optim.lr_scheduler = None,\n",
    "                 epochs: int = 100,\n",
    "                 epoch: int = 0,\n",
    "                 notebook: bool = False\n",
    "                 ):\n",
    "\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.epoch = epoch\n",
    "        self.notebook = notebook\n",
    "\n",
    "        self.training_loss = []\n",
    "        self.validation_loss = []\n",
    "        self.center_pixel_distances = []\n",
    "        self.pixelwise_accuracy = []\n",
    "        self.learning_rate = []\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        progressbar = trange(self.epochs, desc='Progress')\n",
    "        for i in progressbar:\n",
    "\n",
    "            \"\"\"Epoch counter\"\"\"\n",
    "            self.epoch += 1  # epoch counter\n",
    "            \n",
    "            print(f\"[INFO]: Epoch {self.epoch} of {self.epochs}\")\n",
    "\n",
    "            \"\"\"Training block\"\"\"\n",
    "            self._train()\n",
    "\n",
    "            \"\"\"Validation block\"\"\"\n",
    "            if self.validation_DataLoader is not None:\n",
    "                self._validate()\n",
    "                \n",
    "            print(f\"Training loss: {self.training_loss[-1]:.3f}\")\n",
    "            print(f\"Validation loss: {self.validation_loss[-1]:.3f}\")\n",
    "            # save the best model till now if we have the least loss in the current epoch\n",
    "            save_best_model(self.validation_loss[-1], self.epoch, self.model, self.optimizer, self.criterion)\n",
    "            save_model(self.epochs, self.model, self.optimizer, self.criterion, 'outputs_frames_diff/'+'epoch_'+str(self.epoch)+'_model.pth')\n",
    "            save_plots(self.epochs, self.training_loss, self.validation_loss, self.center_pixel_distances, self.pixelwise_accuracy, 'outputs_frames_diff')\n",
    "\n",
    "            print('-'*50)\n",
    "            \n",
    "            \"\"\"Learning rate scheduler block\"\"\"\n",
    "            if self.lr_scheduler is not None:\n",
    "                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':\n",
    "                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss\n",
    "                else:\n",
    "                    self.lr_scheduler.batch()  # learning rate scheduler step\n",
    "        \n",
    "        # save the trained model weights for a final time\n",
    "        save_model(self.epochs, self.model, self.optimizer, self.criterion, 'outputs_frames_diff/final_model.pth')\n",
    "        # save the loss and accuracy plots\n",
    "        save_plots(self.epochs, self.training_loss, self.validation_loss, self.center_pixel_distances, self.pixelwise_accuracy, 'outputs_frames_diff')\n",
    "        print('TRAINING COMPLETE')\n",
    "        return self.training_loss, self.validation_loss, self.learning_rate, self.pixelwise_accuracy, self.center_pixel_distances\n",
    "\n",
    "    def _train(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        self.model.train()  # train mode\n",
    "        train_losses = []  # accumulate the losses here\n",
    "        pixelwise_accuracy_within_batch = []\n",
    "        center_pixel_distance_within_batch = []\n",
    "        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),\n",
    "                          leave=False)\n",
    "\n",
    "        for i, sample_batched in batch_iter:\n",
    "            input, target, labels = sample_batched['image'].to(self.device), sample_batched['mask'].to(self.device), sample_batched['label'].to(self.device)  # send to device (GPU or CPU)\n",
    "            self.optimizer.zero_grad()  # zerograd the parameters\n",
    "            out = self.model(input)  # one forward pass\n",
    "            # out = out[:, np.newaxis, :, :, :]\n",
    "            if i%30 == 0:\n",
    "                save_sample_mask(self.epoch, i, out[0], sample_batched['mask'][0], 'outputs_frames_diff')\n",
    "            loss = self.criterion(out, target)  # calculate loss\n",
    "            loss_value = loss.item()\n",
    "            train_losses.append(loss_value)\n",
    "            pixelwise_accuracy_within_batch.append(get_pixel_accuracy_percent(out, target))\n",
    "            center_pixel_distance_within_batch.append(get_central_pixel_distance(out, labels))\n",
    "            loss.backward()  # one backward pass\n",
    "            self.optimizer.step()  # update the parameters\n",
    "\n",
    "            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar\n",
    "\n",
    "        self.training_loss.append(np.mean(train_losses))\n",
    "        self.pixelwise_accuracy.append(np.mean(pixelwise_accuracy_within_batch))\n",
    "        self.center_pixel_distances.append(np.mean(center_pixel_distance_within_batch))\n",
    "        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        batch_iter.close()\n",
    "\n",
    "    def _validate(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        self.model.eval()  # evaluation mode\n",
    "        valid_losses = []  # accumulate the losses here\n",
    "        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),\n",
    "                          leave=False)\n",
    "\n",
    "        for i, sample_batched in batch_iter:\n",
    "            input, target = sample_batched['image'].to(self.device), sample_batched['mask'].to(self.device)   # send to device (GPU or CPU)\n",
    "\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                out = self.model(input)\n",
    "                loss = self.criterion(out, target)\n",
    "                loss_value = loss.item()\n",
    "                valid_losses.append(loss_value)\n",
    "\n",
    "                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')\n",
    "\n",
    "        self.validation_loss.append(np.mean(valid_losses))\n",
    "\n",
    "        batch_iter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "\n",
    "trainer = TrainerUNET(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=train_dataloader,\n",
    "                  validation_DataLoader=valid_dataloader,\n",
    "                  lr_scheduler=None,\n",
    "                  epochs=EPOCHS,\n",
    "                  epoch=0,\n",
    "                  notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
